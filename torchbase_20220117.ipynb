{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torchbase_20220117.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOt2OVrPr1+D0V+qtBEEdsA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamesLeeeeeee/torchbase/blob/master/torchbase_20220117.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rAei1irmxjez"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w= torch.tensor(2.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "w7krvOIi6aHd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y= w**2\n",
        "z=2*y+5"
      ],
      "metadata": {
        "id": "NfJzU_4q6etj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward()"
      ],
      "metadata": {
        "id": "dUw03K4r7oNj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('수식을 w로 미분한 값 : {}'.format(w.grad))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okOXJkvIBxHh",
        "outputId": "79df92ae-86ef-4370-cd64-52aacbad03c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수식을 w로 미분한 값 : 8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZXQpdfyB8ww",
        "outputId": "34a17d50-b3d1-4409-d5bc-a847e7474b8b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb030a66ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1_train= torch.FloatTensor([[73],[93],[89],[96],[73]])\n",
        "x2_train= torch.FloatTensor([[80],[88],[91],[98],[66]])\n",
        "x3_train= torch.FloatTensor([[75],[93],[90],[100],[70]])\n",
        "y_train= torch.FloatTensor([[152],[185],[180],[196],[142]])"
      ],
      "metadata": {
        "id": "POtcZz8ICvWG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1=torch.zeros(1,requires_grad=True)\n",
        "w2=torch.zeros(1,requires_grad=True)\n",
        "w3=torch.zeros(1,requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)"
      ],
      "metadata": {
        "id": "h94W28SPEjsE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer= optim.SGD([w1,w2,w3,b], lr=1e-5)\n",
        "nb_epochs=1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hypothesis= x1_train*w1+x2_train*w2+x3_train*w3+b\n",
        "\n",
        "  cost= torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} w1:{:.3f} w2:{:.3f} w3:{:.3f} b: {:.3f} Cost:{:.6f}'.format(\n",
        "        epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4FNkkMNEq8B",
        "outputId": "3568245b-4686-4f61-aa58-ee4c019eb791"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 w1:0.718 w2:0.612 w3:0.680 b: 0.009 Cost:1.078964\n",
            "Epoch  100/1000 w1:0.722 w2:0.608 w3:0.680 b: 0.009 Cost:1.038180\n",
            "Epoch  200/1000 w1:0.727 w2:0.603 w3:0.681 b: 0.010 Cost:0.999513\n",
            "Epoch  300/1000 w1:0.731 w2:0.599 w3:0.681 b: 0.010 Cost:0.962859\n",
            "Epoch  400/1000 w1:0.735 w2:0.595 w3:0.681 b: 0.010 Cost:0.928092\n",
            "Epoch  500/1000 w1:0.739 w2:0.590 w3:0.681 b: 0.010 Cost:0.895123\n",
            "Epoch  600/1000 w1:0.743 w2:0.586 w3:0.682 b: 0.010 Cost:0.863870\n",
            "Epoch  700/1000 w1:0.746 w2:0.582 w3:0.682 b: 0.010 Cost:0.834221\n",
            "Epoch  800/1000 w1:0.750 w2:0.579 w3:0.682 b: 0.010 Cost:0.806112\n",
            "Epoch  900/1000 w1:0.754 w2:0.575 w3:0.682 b: 0.010 Cost:0.779432\n",
            "Epoch 1000/1000 w1:0.757 w2:0.571 w3:0.682 b: 0.011 Cost:0.754143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= torch.FloatTensor([[73,80,75],\n",
        "                           [93,88,93],\n",
        "                           [89,91,80],\n",
        "                           [96,98,100],\n",
        "                           [73,66,70]])\n",
        "y_train= torch.FloatTensor([[152],[185],[180],[196],[142]])"
      ],
      "metadata": {
        "id": "pt0FJzlAG0eM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IZB9LQ_ICvV",
        "outputId": "691330be-4647-4ff2-cb38-6d83a78c0b4e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W= torch.zeros((3,1),requires_grad=True)\n",
        "b= torch.zeros(1, requires_grad=True)"
      ],
      "metadata": {
        "id": "G3xU0AWRIKcL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis= x_train.matmul(W)+b"
      ],
      "metadata": {
        "id": "qajpHYpdIft6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer= optim.SGD([W,b], lr=1e-5)\n",
        "nb_epochs=20\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  hypothesis= x_train.matmul(W)+b\n",
        "\n",
        "  cost=torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print('Epoch:{:4d}/ {} hypothesis: {} Cost: {:.6f}'.format(epoch, nb_epochs,\n",
        "                                                             hypothesis.squeeze().detach(),\n",
        "                                                             cost.item())\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMlB2I3DIqDS",
        "outputId": "1bb1dfe4-9064-4147-aeae-bf207b14964d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   0/ 20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
            "Epoch:   1/ 20 hypothesis: tensor([66.7178, 80.1701, 76.1025, 86.0194, 61.1565]) Cost: 9537.694336\n",
            "Epoch:   2/ 20 hypothesis: tensor([104.5421, 125.6208, 119.2478, 134.7862,  95.8280]) Cost: 3069.590088\n",
            "Epoch:   3/ 20 hypothesis: tensor([125.9858, 151.3882, 143.7087, 162.4333, 115.4844]) Cost: 990.670288\n",
            "Epoch:   4/ 20 hypothesis: tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]) Cost: 322.481873\n",
            "Epoch:   5/ 20 hypothesis: tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]) Cost: 107.717064\n",
            "Epoch:   6/ 20 hypothesis: tensor([148.9423, 178.9730, 169.8976, 192.0301, 136.5279]) Cost: 38.687496\n",
            "Epoch:   7/ 20 hypothesis: tensor([151.1574, 181.6346, 172.4254, 194.8856, 138.5585]) Cost: 16.499043\n",
            "Epoch:   8/ 20 hypothesis: tensor([152.4131, 183.1435, 173.8590, 196.5043, 139.7097]) Cost: 9.365656\n",
            "Epoch:   9/ 20 hypothesis: tensor([153.1250, 183.9988, 174.6723, 197.4217, 140.3625]) Cost: 7.071114\n",
            "Epoch:  10/ 20 hypothesis: tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]) Cost: 6.331847\n",
            "Epoch:  11/ 20 hypothesis: tensor([153.7572, 184.7582, 175.3958, 198.2360, 140.9424]) Cost: 6.092532\n",
            "Epoch:  12/ 20 hypothesis: tensor([153.8868, 184.9138, 175.5449, 198.4026, 141.0613]) Cost: 6.013817\n",
            "Epoch:  13/ 20 hypothesis: tensor([153.9602, 185.0019, 175.6299, 198.4969, 141.1288]) Cost: 5.986785\n",
            "Epoch:  14/ 20 hypothesis: tensor([154.0017, 185.0517, 175.6785, 198.5500, 141.1671]) Cost: 5.976325\n",
            "Epoch:  15/ 20 hypothesis: tensor([154.0252, 185.0798, 175.7065, 198.5800, 141.1888]) Cost: 5.971208\n",
            "Epoch:  16/ 20 hypothesis: tensor([154.0385, 185.0956, 175.7229, 198.5966, 141.2012]) Cost: 5.967835\n",
            "Epoch:  17/ 20 hypothesis: tensor([154.0459, 185.1045, 175.7326, 198.6059, 141.2082]) Cost: 5.964969\n",
            "Epoch:  18/ 20 hypothesis: tensor([154.0501, 185.1094, 175.7386, 198.6108, 141.2122]) Cost: 5.962291\n",
            "Epoch:  19/ 20 hypothesis: tensor([154.0524, 185.1120, 175.7424, 198.6134, 141.2145]) Cost: 5.959664\n",
            "Epoch:  20/ 20 hypothesis: tensor([154.0536, 185.1134, 175.7451, 198.6145, 141.2158]) Cost: 5.957089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Olx6c7HrJckX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCtdAUWAJ7RD",
        "outputId": "079665ec-2459-420a-a937-0bc2845148fd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb030a66ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= torch.FloatTensor([[1],[2],[3]])\n",
        "y_train= torch.FloatTensor([[2],[4],[6]])"
      ],
      "metadata": {
        "id": "zNxrvZ0yKIy-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=nn.Linear(1,1)"
      ],
      "metadata": {
        "id": "ag1YeVQCKWFE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "advYanSXL579",
        "outputId": "a23bb99f-e5da-48ce-a9da-5ad4bc241b61"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer= torch.optim.SGD(model.parameters(), lr= 0.01)"
      ],
      "metadata": {
        "id": "qtLxLjzGMFHP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs= 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction= model(x_train)\n",
        "\n",
        "  cost=F.mse_loss(prediction, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch %100==0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9zfJueSMUn0",
        "outputId": "c957b48c-55de-4c4d-f982-5e51eb676240"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_var= torch.FloatTensor([[4.0]])"
      ],
      "metadata": {
        "id": "qXnRsgVMM4Id"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y= model(new_var)"
      ],
      "metadata": {
        "id": "b6pw4fH4NNwp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 후 입력이 4일 때의 예측값 :', pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csvDBy8jNP01",
        "outputId": "933da9b2-4bb1-4568-d32c-d712b9c5f983"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 4일 때의 예측값 : tensor([[7.9989]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuHLkQp8NVXl",
        "outputId": "2e1ea760-a928-4290-8718-759ee41fca63"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w1wC-eDNmr_",
        "outputId": "89b628fb-4e70-4a9d-9c95-d4ceb8a8a20e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7effcd8dbeb0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= torch.FloatTensor([[73,80,75],\n",
        "                            [93,88,93],\n",
        "                            [89,91,90],\n",
        "                            [96,98,100],\n",
        "                            [73,66,70]])\n",
        "y_train= torch.FloatTensor([[152],[185],[180],[196],[142]])"
      ],
      "metadata": {
        "id": "CMFmQizlOBcv"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= nn.Linear(3,1)"
      ],
      "metadata": {
        "id": "Ka8hC-y8OTeO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN7yTJtROa6W",
        "outputId": "78dd721d-b2e1-4999-b18a-0b86328218f0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2710], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=torch.optim.SGD(model.parameters(),lr=1e-5)\n",
        "optimizer_test=torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "7_yVODMLOjYV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs= 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction= model(x_train)\n",
        "\n",
        "  cost= F.mse_loss(prediction, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch% 100==0:\n",
        "    print('Epoch: {:4d}/ {} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIZgVRq0O5Df",
        "outputId": "ef86a321-2666-4b50-957e-01605b953e44"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    0/ 2000 Cost: 31667.597656\n",
            "Epoch:  100/ 2000 Cost: 0.225993\n",
            "Epoch:  200/ 2000 Cost: 0.223911\n",
            "Epoch:  300/ 2000 Cost: 0.221941\n",
            "Epoch:  400/ 2000 Cost: 0.220059\n",
            "Epoch:  500/ 2000 Cost: 0.218271\n",
            "Epoch:  600/ 2000 Cost: 0.216575\n",
            "Epoch:  700/ 2000 Cost: 0.214950\n",
            "Epoch:  800/ 2000 Cost: 0.213413\n",
            "Epoch:  900/ 2000 Cost: 0.211952\n",
            "Epoch: 1000/ 2000 Cost: 0.210560\n",
            "Epoch: 1100/ 2000 Cost: 0.209232\n",
            "Epoch: 1200/ 2000 Cost: 0.207967\n",
            "Epoch: 1300/ 2000 Cost: 0.206761\n",
            "Epoch: 1400/ 2000 Cost: 0.205619\n",
            "Epoch: 1500/ 2000 Cost: 0.204522\n",
            "Epoch: 1600/ 2000 Cost: 0.203484\n",
            "Epoch: 1700/ 2000 Cost: 0.202485\n",
            "Epoch: 1800/ 2000 Cost: 0.201542\n",
            "Epoch: 1900/ 2000 Cost: 0.200635\n",
            "Epoch: 2000/ 2000 Cost: 0.199769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_var= torch.FloatTensor([[73,80,75]])\n",
        "pred_y= model(new_var)\n",
        "print('훈련 후 입력이 73,80,75 일 때의 예측값 :', pred_y\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jai-Lzp0PXpI",
        "outputId": "aa82a4b2-5f5e-49d2-dd0b-19c879184bff"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 73,80,75 일 때의 예측값 : tensor([[151.2305]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBF_VHHEPoMW",
        "outputId": "a7984db4-4370-445c-8801-3b966e2d35ec"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2802], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs=2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction=model(x_train)\n",
        "  cost= F.mse_loss(prediction, y_train)\n",
        "\n",
        "  optimizer_test.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer_test.step()\n",
        "  \n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35_WtzJEPupX",
        "outputId": "fd1a94ba-dffa-4814-bf74-1b799ee678a9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 0.199762\n",
            "Epoch  100/2000 Cost: nan\n",
            "Epoch  200/2000 Cost: nan\n",
            "Epoch  300/2000 Cost: nan\n",
            "Epoch  400/2000 Cost: nan\n",
            "Epoch  500/2000 Cost: nan\n",
            "Epoch  600/2000 Cost: nan\n",
            "Epoch  700/2000 Cost: nan\n",
            "Epoch  800/2000 Cost: nan\n",
            "Epoch  900/2000 Cost: nan\n",
            "Epoch 1000/2000 Cost: nan\n",
            "Epoch 1100/2000 Cost: nan\n",
            "Epoch 1200/2000 Cost: nan\n",
            "Epoch 1300/2000 Cost: nan\n",
            "Epoch 1400/2000 Cost: nan\n",
            "Epoch 1500/2000 Cost: nan\n",
            "Epoch 1600/2000 Cost: nan\n",
            "Epoch 1700/2000 Cost: nan\n",
            "Epoch 1800/2000 Cost: nan\n",
            "Epoch 1900/2000 Cost: nan\n",
            "Epoch 2000/2000 Cost: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_var= torch.FloatTensor([[73,80,75]])\n",
        "pred_y= model(new_var)\n",
        "print('훈련 후 입력이 73,80,75 일 때의 예측값 :', pred_y\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWq34jpSc1D4",
        "outputId": "312a0920-eb92-4bce-ba68-d0696786b5df"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 73,80,75 일 때의 예측값 : tensor([[nan]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlzc9idmc-AQ",
        "outputId": "54deb192-c824-438c-e828-459701fe5049"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[nan, nan, nan]], requires_grad=True), Parameter containing:\n",
            "tensor([nan], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= nn.Linear(1,1)"
      ],
      "metadata": {
        "id": "RE6_VsZWdAA-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(1,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.linear(x)"
      ],
      "metadata": {
        "id": "PRQDslyHl8a9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=LinearRegressionModel()"
      ],
      "metadata": {
        "id": "e-R857h8SZ6w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=nn.Linear(3,1)"
      ],
      "metadata": {
        "id": "_T_hwZj6cNFf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear= nn.Linear(3,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return sefl.linear(x)"
      ],
      "metadata": {
        "id": "10LRqr8Scd4W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= MultivariateLinearRegressionModel()"
      ],
      "metadata": {
        "id": "5ASuRKcWcyiO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krTjuVC6c0el",
        "outputId": "53ce00bd-40d1-41f0-cba1-f7c23cda3cca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7effcd8dbeb0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train= torch.FloatTensor([[1],[2],[3]])\n",
        "y_train= torch.FloatTensor([[2],[4],[6]])"
      ],
      "metadata": {
        "id": "UeowVQDwc95l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear=nn.Linear(1,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "model= LinearRegressionModel()"
      ],
      "metadata": {
        "id": "BdtjfnWDdFyW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer= torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "uUqi0oBBdZEM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs= 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction= model(x_train)\n",
        "  cost= F.mse_loss(prediction, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "\n",
        "    print('Epoch: {:4d}/{} Cost: {:.5f}'.format(epoch, nb_epochs, cost.item())\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfT-9zQLdf81",
        "outputId": "c57eecef-4435-403b-b5dd-d3150b149121"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    0/2000 Cost: 13.10354\n",
            "Epoch:  100/2000 Cost: 0.00279\n",
            "Epoch:  200/2000 Cost: 0.00172\n",
            "Epoch:  300/2000 Cost: 0.00107\n",
            "Epoch:  400/2000 Cost: 0.00066\n",
            "Epoch:  500/2000 Cost: 0.00041\n",
            "Epoch:  600/2000 Cost: 0.00025\n",
            "Epoch:  700/2000 Cost: 0.00016\n",
            "Epoch:  800/2000 Cost: 0.00010\n",
            "Epoch:  900/2000 Cost: 0.00006\n",
            "Epoch: 1000/2000 Cost: 0.00004\n",
            "Epoch: 1100/2000 Cost: 0.00002\n",
            "Epoch: 1200/2000 Cost: 0.00001\n",
            "Epoch: 1300/2000 Cost: 0.00001\n",
            "Epoch: 1400/2000 Cost: 0.00001\n",
            "Epoch: 1500/2000 Cost: 0.00000\n",
            "Epoch: 1600/2000 Cost: 0.00000\n",
            "Epoch: 1700/2000 Cost: 0.00000\n",
            "Epoch: 1800/2000 Cost: 0.00000\n",
            "Epoch: 1900/2000 Cost: 0.00000\n",
            "Epoch: 2000/2000 Cost: 0.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwI0msF-eDgv",
        "outputId": "41b83258-91f4-4765-c6d2-0ed6c0fa46aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e2P9k7KebUG",
        "outputId": "f828be57-8dac-4e93-8b63-a089f1061fde"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7effcd8dbeb0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=torch.FloatTensor([[73,80,75],\n",
        "                           [93,88,93],\n",
        "                           [89,91,90],\n",
        "                           [96,98,100],\n",
        "                           [73,66,70]])\n",
        "y_train= torch.FloatTensor([[152],[185],[180],[196],[142]])"
      ],
      "metadata": {
        "id": "fcML0cbweqVm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear= nn.Linear(3,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "metadata": {
        "id": "g1o-aicYe8hn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= MultivariateLinearRegressionModel()\n",
        "optimizer= torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "LIeDWq3ZfQXn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs=20000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  cost=F.mse_loss(prediction, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print('Epoch : {:4d}/ {} Cost: {:.5f}'.format(epoch, nb_epochs, cost.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-PJuOIyfY0n",
        "outputId": "89e367e4-3b08-4b35-8959-31c8b7616040"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :    0/ 20000 Cost: 9926.26562\n",
            "Epoch :  100/ 20000 Cost: 0.22597\n",
            "Epoch :  200/ 20000 Cost: 0.22390\n",
            "Epoch :  300/ 20000 Cost: 0.22192\n",
            "Epoch :  400/ 20000 Cost: 0.22004\n",
            "Epoch :  500/ 20000 Cost: 0.21825\n",
            "Epoch :  600/ 20000 Cost: 0.21655\n",
            "Epoch :  700/ 20000 Cost: 0.21494\n",
            "Epoch :  800/ 20000 Cost: 0.21340\n",
            "Epoch :  900/ 20000 Cost: 0.21194\n",
            "Epoch : 1000/ 20000 Cost: 0.21055\n",
            "Epoch : 1100/ 20000 Cost: 0.20922\n",
            "Epoch : 1200/ 20000 Cost: 0.20796\n",
            "Epoch : 1300/ 20000 Cost: 0.20676\n",
            "Epoch : 1400/ 20000 Cost: 0.20560\n",
            "Epoch : 1500/ 20000 Cost: 0.20451\n",
            "Epoch : 1600/ 20000 Cost: 0.20347\n",
            "Epoch : 1700/ 20000 Cost: 0.20247\n",
            "Epoch : 1800/ 20000 Cost: 0.20153\n",
            "Epoch : 1900/ 20000 Cost: 0.20063\n",
            "Epoch : 2000/ 20000 Cost: 0.19976\n",
            "Epoch : 2100/ 20000 Cost: 0.19894\n",
            "Epoch : 2200/ 20000 Cost: 0.19815\n",
            "Epoch : 2300/ 20000 Cost: 0.19740\n",
            "Epoch : 2400/ 20000 Cost: 0.19668\n",
            "Epoch : 2500/ 20000 Cost: 0.19599\n",
            "Epoch : 2600/ 20000 Cost: 0.19533\n",
            "Epoch : 2700/ 20000 Cost: 0.19471\n",
            "Epoch : 2800/ 20000 Cost: 0.19410\n",
            "Epoch : 2900/ 20000 Cost: 0.19353\n",
            "Epoch : 3000/ 20000 Cost: 0.19298\n",
            "Epoch : 3100/ 20000 Cost: 0.19245\n",
            "Epoch : 3200/ 20000 Cost: 0.19194\n",
            "Epoch : 3300/ 20000 Cost: 0.19145\n",
            "Epoch : 3400/ 20000 Cost: 0.19098\n",
            "Epoch : 3500/ 20000 Cost: 0.19054\n",
            "Epoch : 3600/ 20000 Cost: 0.19011\n",
            "Epoch : 3700/ 20000 Cost: 0.18969\n",
            "Epoch : 3800/ 20000 Cost: 0.18929\n",
            "Epoch : 3900/ 20000 Cost: 0.18891\n",
            "Epoch : 4000/ 20000 Cost: 0.18854\n",
            "Epoch : 4100/ 20000 Cost: 0.18818\n",
            "Epoch : 4200/ 20000 Cost: 0.18784\n",
            "Epoch : 4300/ 20000 Cost: 0.18751\n",
            "Epoch : 4400/ 20000 Cost: 0.18719\n",
            "Epoch : 4500/ 20000 Cost: 0.18689\n",
            "Epoch : 4600/ 20000 Cost: 0.18659\n",
            "Epoch : 4700/ 20000 Cost: 0.18630\n",
            "Epoch : 4800/ 20000 Cost: 0.18602\n",
            "Epoch : 4900/ 20000 Cost: 0.18575\n",
            "Epoch : 5000/ 20000 Cost: 0.18549\n",
            "Epoch : 5100/ 20000 Cost: 0.18523\n",
            "Epoch : 5200/ 20000 Cost: 0.18499\n",
            "Epoch : 5300/ 20000 Cost: 0.18476\n",
            "Epoch : 5400/ 20000 Cost: 0.18453\n",
            "Epoch : 5500/ 20000 Cost: 0.18430\n",
            "Epoch : 5600/ 20000 Cost: 0.18409\n",
            "Epoch : 5700/ 20000 Cost: 0.18388\n",
            "Epoch : 5800/ 20000 Cost: 0.18367\n",
            "Epoch : 5900/ 20000 Cost: 0.18347\n",
            "Epoch : 6000/ 20000 Cost: 0.18327\n",
            "Epoch : 6100/ 20000 Cost: 0.18309\n",
            "Epoch : 6200/ 20000 Cost: 0.18290\n",
            "Epoch : 6300/ 20000 Cost: 0.18272\n",
            "Epoch : 6400/ 20000 Cost: 0.18254\n",
            "Epoch : 6500/ 20000 Cost: 0.18237\n",
            "Epoch : 6600/ 20000 Cost: 0.18220\n",
            "Epoch : 6700/ 20000 Cost: 0.18203\n",
            "Epoch : 6800/ 20000 Cost: 0.18187\n",
            "Epoch : 6900/ 20000 Cost: 0.18172\n",
            "Epoch : 7000/ 20000 Cost: 0.18156\n",
            "Epoch : 7100/ 20000 Cost: 0.18141\n",
            "Epoch : 7200/ 20000 Cost: 0.18126\n",
            "Epoch : 7300/ 20000 Cost: 0.18111\n",
            "Epoch : 7400/ 20000 Cost: 0.18097\n",
            "Epoch : 7500/ 20000 Cost: 0.18083\n",
            "Epoch : 7600/ 20000 Cost: 0.18069\n",
            "Epoch : 7700/ 20000 Cost: 0.18056\n",
            "Epoch : 7800/ 20000 Cost: 0.18042\n",
            "Epoch : 7900/ 20000 Cost: 0.18029\n",
            "Epoch : 8000/ 20000 Cost: 0.18016\n",
            "Epoch : 8100/ 20000 Cost: 0.18003\n",
            "Epoch : 8200/ 20000 Cost: 0.17991\n",
            "Epoch : 8300/ 20000 Cost: 0.17978\n",
            "Epoch : 8400/ 20000 Cost: 0.17966\n",
            "Epoch : 8500/ 20000 Cost: 0.17954\n",
            "Epoch : 8600/ 20000 Cost: 0.17942\n",
            "Epoch : 8700/ 20000 Cost: 0.17930\n",
            "Epoch : 8800/ 20000 Cost: 0.17919\n",
            "Epoch : 8900/ 20000 Cost: 0.17907\n",
            "Epoch : 9000/ 20000 Cost: 0.17896\n",
            "Epoch : 9100/ 20000 Cost: 0.17885\n",
            "Epoch : 9200/ 20000 Cost: 0.17874\n",
            "Epoch : 9300/ 20000 Cost: 0.17862\n",
            "Epoch : 9400/ 20000 Cost: 0.17852\n",
            "Epoch : 9500/ 20000 Cost: 0.17841\n",
            "Epoch : 9600/ 20000 Cost: 0.17831\n",
            "Epoch : 9700/ 20000 Cost: 0.17820\n",
            "Epoch : 9800/ 20000 Cost: 0.17810\n",
            "Epoch : 9900/ 20000 Cost: 0.17799\n",
            "Epoch : 10000/ 20000 Cost: 0.17789\n",
            "Epoch : 10100/ 20000 Cost: 0.17779\n",
            "Epoch : 10200/ 20000 Cost: 0.17769\n",
            "Epoch : 10300/ 20000 Cost: 0.17759\n",
            "Epoch : 10400/ 20000 Cost: 0.17749\n",
            "Epoch : 10500/ 20000 Cost: 0.17740\n",
            "Epoch : 10600/ 20000 Cost: 0.17730\n",
            "Epoch : 10700/ 20000 Cost: 0.17720\n",
            "Epoch : 10800/ 20000 Cost: 0.17711\n",
            "Epoch : 10900/ 20000 Cost: 0.17702\n",
            "Epoch : 11000/ 20000 Cost: 0.17692\n",
            "Epoch : 11100/ 20000 Cost: 0.17683\n",
            "Epoch : 11200/ 20000 Cost: 0.17674\n",
            "Epoch : 11300/ 20000 Cost: 0.17665\n",
            "Epoch : 11400/ 20000 Cost: 0.17656\n",
            "Epoch : 11500/ 20000 Cost: 0.17647\n",
            "Epoch : 11600/ 20000 Cost: 0.17638\n",
            "Epoch : 11700/ 20000 Cost: 0.17629\n",
            "Epoch : 11800/ 20000 Cost: 0.17620\n",
            "Epoch : 11900/ 20000 Cost: 0.17611\n",
            "Epoch : 12000/ 20000 Cost: 0.17602\n",
            "Epoch : 12100/ 20000 Cost: 0.17594\n",
            "Epoch : 12200/ 20000 Cost: 0.17586\n",
            "Epoch : 12300/ 20000 Cost: 0.17577\n",
            "Epoch : 12400/ 20000 Cost: 0.17568\n",
            "Epoch : 12500/ 20000 Cost: 0.17560\n",
            "Epoch : 12600/ 20000 Cost: 0.17551\n",
            "Epoch : 12700/ 20000 Cost: 0.17543\n",
            "Epoch : 12800/ 20000 Cost: 0.17535\n",
            "Epoch : 12900/ 20000 Cost: 0.17527\n",
            "Epoch : 13000/ 20000 Cost: 0.17519\n",
            "Epoch : 13100/ 20000 Cost: 0.17510\n",
            "Epoch : 13200/ 20000 Cost: 0.17503\n",
            "Epoch : 13300/ 20000 Cost: 0.17495\n",
            "Epoch : 13400/ 20000 Cost: 0.17487\n",
            "Epoch : 13500/ 20000 Cost: 0.17479\n",
            "Epoch : 13600/ 20000 Cost: 0.17470\n",
            "Epoch : 13700/ 20000 Cost: 0.17463\n",
            "Epoch : 13800/ 20000 Cost: 0.17455\n",
            "Epoch : 13900/ 20000 Cost: 0.17447\n",
            "Epoch : 14000/ 20000 Cost: 0.17440\n",
            "Epoch : 14100/ 20000 Cost: 0.17432\n",
            "Epoch : 14200/ 20000 Cost: 0.17424\n",
            "Epoch : 14300/ 20000 Cost: 0.17417\n",
            "Epoch : 14400/ 20000 Cost: 0.17409\n",
            "Epoch : 14500/ 20000 Cost: 0.17402\n",
            "Epoch : 14600/ 20000 Cost: 0.17394\n",
            "Epoch : 14700/ 20000 Cost: 0.17386\n",
            "Epoch : 14800/ 20000 Cost: 0.17379\n",
            "Epoch : 14900/ 20000 Cost: 0.17372\n",
            "Epoch : 15000/ 20000 Cost: 0.17365\n",
            "Epoch : 15100/ 20000 Cost: 0.17358\n",
            "Epoch : 15200/ 20000 Cost: 0.17350\n",
            "Epoch : 15300/ 20000 Cost: 0.17343\n",
            "Epoch : 15400/ 20000 Cost: 0.17336\n",
            "Epoch : 15500/ 20000 Cost: 0.17328\n",
            "Epoch : 15600/ 20000 Cost: 0.17322\n",
            "Epoch : 15700/ 20000 Cost: 0.17314\n",
            "Epoch : 15800/ 20000 Cost: 0.17308\n",
            "Epoch : 15900/ 20000 Cost: 0.17301\n",
            "Epoch : 16000/ 20000 Cost: 0.17294\n",
            "Epoch : 16100/ 20000 Cost: 0.17286\n",
            "Epoch : 16200/ 20000 Cost: 0.17280\n",
            "Epoch : 16300/ 20000 Cost: 0.17273\n",
            "Epoch : 16400/ 20000 Cost: 0.17266\n",
            "Epoch : 16500/ 20000 Cost: 0.17259\n",
            "Epoch : 16600/ 20000 Cost: 0.17253\n",
            "Epoch : 16700/ 20000 Cost: 0.17246\n",
            "Epoch : 16800/ 20000 Cost: 0.17239\n",
            "Epoch : 16900/ 20000 Cost: 0.17233\n",
            "Epoch : 17000/ 20000 Cost: 0.17226\n",
            "Epoch : 17100/ 20000 Cost: 0.17220\n",
            "Epoch : 17200/ 20000 Cost: 0.17214\n",
            "Epoch : 17300/ 20000 Cost: 0.17206\n",
            "Epoch : 17400/ 20000 Cost: 0.17201\n",
            "Epoch : 17500/ 20000 Cost: 0.17194\n",
            "Epoch : 17600/ 20000 Cost: 0.17188\n",
            "Epoch : 17700/ 20000 Cost: 0.17181\n",
            "Epoch : 17800/ 20000 Cost: 0.17175\n",
            "Epoch : 17900/ 20000 Cost: 0.17168\n",
            "Epoch : 18000/ 20000 Cost: 0.17163\n",
            "Epoch : 18100/ 20000 Cost: 0.17156\n",
            "Epoch : 18200/ 20000 Cost: 0.17150\n",
            "Epoch : 18300/ 20000 Cost: 0.17143\n",
            "Epoch : 18400/ 20000 Cost: 0.17137\n",
            "Epoch : 18500/ 20000 Cost: 0.17131\n",
            "Epoch : 18600/ 20000 Cost: 0.17125\n",
            "Epoch : 18700/ 20000 Cost: 0.17118\n",
            "Epoch : 18800/ 20000 Cost: 0.17112\n",
            "Epoch : 18900/ 20000 Cost: 0.17106\n",
            "Epoch : 19000/ 20000 Cost: 0.17101\n",
            "Epoch : 19100/ 20000 Cost: 0.17095\n",
            "Epoch : 19200/ 20000 Cost: 0.17089\n",
            "Epoch : 19300/ 20000 Cost: 0.17083\n",
            "Epoch : 19400/ 20000 Cost: 0.17077\n",
            "Epoch : 19500/ 20000 Cost: 0.17071\n",
            "Epoch : 19600/ 20000 Cost: 0.17065\n",
            "Epoch : 19700/ 20000 Cost: 0.17059\n",
            "Epoch : 19800/ 20000 Cost: 0.17054\n",
            "Epoch : 19900/ 20000 Cost: 0.17048\n",
            "Epoch : 20000/ 20000 Cost: 0.17042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8eMIS4JgBe5",
        "outputId": "6a6942c4-1130-446a-a297-e30e61f3f94e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.9873, 0.4919, 0.5298]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2900], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "F_Xbc60mgMiA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  90], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ],
      "metadata": {
        "id": "A2askokogzCq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=TensorDataset(x_train,y_train)"
      ],
      "metadata": {
        "id": "TSz_KxGIg01g"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader= DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "LpfEIlVSg4m5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=nn.Linear(3,1)\n",
        "optimizer= torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "QkjFgVXVhNvI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs=20\n",
        "for epoch in range(nb_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    print(batch_idx)\n",
        "    print(samples)\n",
        "    x_train, y_train = samples\n",
        "\n",
        "    prediction=model(x_train)\n",
        "    cost= F.mse_loss(prediction, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch: {:4d}/{} Batch:{}/{} Cost: {:.5f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader), cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwX_lc61hXRp",
        "outputId": "ca80efcd-ba05-4061-f5c7-c9b0f93041ea"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[tensor([[93., 88., 93.],\n",
            "        [73., 80., 75.]]), tensor([[185.],\n",
            "        [152.]])]\n",
            "Epoch:    0/20 Batch:1/3 Cost: 13.74888\n",
            "1\n",
            "[tensor([[ 73.,  66.,  70.],\n",
            "        [ 96.,  98., 100.]]), tensor([[142.],\n",
            "        [196.]])]\n",
            "Epoch:    0/20 Batch:2/3 Cost: 13.72004\n",
            "2\n",
            "[tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
            "Epoch:    0/20 Batch:3/3 Cost: 4.19145\n",
            "0\n",
            "[tensor([[73., 66., 70.],\n",
            "        [93., 88., 93.]]), tensor([[142.],\n",
            "        [185.]])]\n",
            "Epoch:    1/20 Batch:1/3 Cost: 23.27919\n",
            "1\n",
            "[tensor([[ 89.,  91.,  90.],\n",
            "        [ 96.,  98., 100.]]), tensor([[180.],\n",
            "        [196.]])]\n",
            "Epoch:    1/20 Batch:2/3 Cost: 10.13991\n",
            "2\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch:    1/20 Batch:3/3 Cost: 12.42472\n",
            "0\n",
            "[tensor([[93., 88., 93.],\n",
            "        [89., 91., 90.]]), tensor([[185.],\n",
            "        [180.]])]\n",
            "Epoch:    2/20 Batch:1/3 Cost: 13.76364\n",
            "1\n",
            "[tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  80.,  75.]]), tensor([[196.],\n",
            "        [152.]])]\n",
            "Epoch:    2/20 Batch:2/3 Cost: 6.61229\n",
            "2\n",
            "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
            "Epoch:    2/20 Batch:3/3 Cost: 35.48186\n",
            "0\n",
            "[tensor([[73., 80., 75.],\n",
            "        [93., 88., 93.]]), tensor([[152.],\n",
            "        [185.]])]\n",
            "Epoch:    3/20 Batch:1/3 Cost: 13.35474\n",
            "1\n",
            "[tensor([[89., 91., 90.],\n",
            "        [73., 66., 70.]]), tensor([[180.],\n",
            "        [142.]])]\n",
            "Epoch:    3/20 Batch:2/3 Cost: 12.26735\n",
            "2\n",
            "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
            "Epoch:    3/20 Batch:3/3 Cost: 7.14821\n",
            "0\n",
            "[tensor([[93., 88., 93.],\n",
            "        [73., 66., 70.]]), tensor([[185.],\n",
            "        [142.]])]\n",
            "Epoch:    4/20 Batch:1/3 Cost: 22.40242\n",
            "1\n",
            "[tensor([[73., 80., 75.],\n",
            "        [89., 91., 90.]]), tensor([[152.],\n",
            "        [180.]])]\n",
            "Epoch:    4/20 Batch:2/3 Cost: 17.07132\n",
            "2\n",
            "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
            "Epoch:    4/20 Batch:3/3 Cost: 1.91931\n",
            "0\n",
            "[tensor([[ 89.,  91.,  90.],\n",
            "        [ 96.,  98., 100.]]), tensor([[180.],\n",
            "        [196.]])]\n",
            "Epoch:    5/20 Batch:1/3 Cost: 0.37689\n",
            "1\n",
            "[tensor([[93., 88., 93.],\n",
            "        [73., 66., 70.]]), tensor([[185.],\n",
            "        [142.]])]\n",
            "Epoch:    5/20 Batch:2/3 Cost: 29.60522\n",
            "2\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch:    5/20 Batch:3/3 Cost: 20.27720\n",
            "0\n",
            "[tensor([[73., 80., 75.],\n",
            "        [89., 91., 90.]]), tensor([[152.],\n",
            "        [180.]])]\n",
            "Epoch:    6/20 Batch:1/3 Cost: 4.64785\n",
            "1\n",
            "[tensor([[ 96.,  98., 100.],\n",
            "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
            "        [185.]])]\n",
            "Epoch:    6/20 Batch:2/3 Cost: 13.82393\n",
            "2\n",
            "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
            "Epoch:    6/20 Batch:3/3 Cost: 26.20841\n",
            "0\n",
            "[tensor([[ 96.,  98., 100.],\n",
            "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
            "        [185.]])]\n",
            "Epoch:    7/20 Batch:1/3 Cost: 7.82006\n",
            "1\n",
            "[tensor([[73., 66., 70.],\n",
            "        [73., 80., 75.]]), tensor([[142.],\n",
            "        [152.]])]\n",
            "Epoch:    7/20 Batch:2/3 Cost: 18.60409\n",
            "2\n",
            "[tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
            "Epoch:    7/20 Batch:3/3 Cost: 6.86238\n",
            "0\n",
            "[tensor([[93., 88., 93.],\n",
            "        [73., 66., 70.]]), tensor([[185.],\n",
            "        [142.]])]\n",
            "Epoch:    8/20 Batch:1/3 Cost: 20.57976\n",
            "1\n",
            "[tensor([[ 89.,  91.,  90.],\n",
            "        [ 96.,  98., 100.]]), tensor([[180.],\n",
            "        [196.]])]\n",
            "Epoch:    8/20 Batch:2/3 Cost: 11.27052\n",
            "2\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch:    8/20 Batch:3/3 Cost: 12.72611\n",
            "0\n",
            "[tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  66.,  70.]]), tensor([[196.],\n",
            "        [142.]])]\n",
            "Epoch:    9/20 Batch:1/3 Cost: 18.38677\n",
            "1\n",
            "[tensor([[73., 80., 75.],\n",
            "        [93., 88., 93.]]), tensor([[152.],\n",
            "        [185.]])]\n",
            "Epoch:    9/20 Batch:2/3 Cost: 13.40863\n",
            "2\n",
            "[tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
            "Epoch:    9/20 Batch:3/3 Cost: 2.39060\n",
            "0\n",
            "[tensor([[89., 91., 90.],\n",
            "        [73., 66., 70.]]), tensor([[180.],\n",
            "        [142.]])]\n",
            "Epoch:   10/20 Batch:1/3 Cost: 15.54169\n",
            "1\n",
            "[tensor([[ 73.,  80.,  75.],\n",
            "        [ 96.,  98., 100.]]), tensor([[152.],\n",
            "        [196.]])]\n",
            "Epoch:   10/20 Batch:2/3 Cost: 7.99386\n",
            "2\n",
            "[tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
            "Epoch:   10/20 Batch:3/3 Cost: 22.95149\n",
            "0\n",
            "[tensor([[93., 88., 93.],\n",
            "        [73., 80., 75.]]), tensor([[185.],\n",
            "        [152.]])]\n",
            "Epoch:   11/20 Batch:1/3 Cost: 13.52364\n",
            "1\n",
            "[tensor([[73., 66., 70.],\n",
            "        [89., 91., 90.]]), tensor([[142.],\n",
            "        [180.]])]\n",
            "Epoch:   11/20 Batch:2/3 Cost: 11.94394\n",
            "2\n",
            "[tensor([[ 96.,  98., 100.]]), tensor([[196.]])]\n",
            "Epoch:   11/20 Batch:3/3 Cost: 7.73713\n",
            "0\n",
            "[tensor([[ 93.,  88.,  93.],\n",
            "        [ 96.,  98., 100.]]), tensor([[185.],\n",
            "        [196.]])]\n",
            "Epoch:   12/20 Batch:1/3 Cost: 8.87357\n",
            "1\n",
            "[tensor([[89., 91., 90.],\n",
            "        [73., 66., 70.]]), tensor([[180.],\n",
            "        [142.]])]\n",
            "Epoch:   12/20 Batch:2/3 Cost: 12.68827\n",
            "2\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch:   12/20 Batch:3/3 Cost: 17.42938\n",
            "0\n",
            "[tensor([[73., 66., 70.],\n",
            "        [93., 88., 93.]]), tensor([[142.],\n",
            "        [185.]])]\n",
            "Epoch:   13/20 Batch:1/3 Cost: 26.90174\n",
            "1\n",
            "[tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  80.,  75.]]), tensor([[196.],\n",
            "        [152.]])]\n",
            "Epoch:   13/20 Batch:2/3 Cost: 14.85044\n",
            "2\n",
            "[tensor([[89., 91., 90.]]), tensor([[180.]])]\n",
            "Epoch:   13/20 Batch:3/3 Cost: 1.15005\n",
            "0\n",
            "[tensor([[73., 66., 70.],\n",
            "        [89., 91., 90.]]), tensor([[142.],\n",
            "        [180.]])]\n",
            "Epoch:   14/20 Batch:1/3 Cost: 16.32996\n",
            "1\n",
            "[tensor([[ 96.,  98., 100.],\n",
            "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
            "        [185.]])]\n",
            "Epoch:   14/20 Batch:2/3 Cost: 8.07749\n",
            "2\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch:   14/20 Batch:3/3 Cost: 15.41032\n",
            "0\n",
            "[tensor([[73., 66., 70.],\n",
            "        [93., 88., 93.]]), tensor([[142.],\n",
            "        [185.]])]\n",
            "Epoch:   15/20 Batch:1/3 Cost: 28.52151\n",
            "1\n",
            "[tensor([[ 96.,  98., 100.],\n",
            "        [ 89.,  91.,  90.]]), tensor([[196.],\n",
            "        [180.]])]\n",
            "Epoch:   15/20 Batch:2/3 Cost: 7.52264\n",
            "2\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch:   15/20 Batch:3/3 Cost: 10.96932\n",
            "0\n",
            "[tensor([[89., 91., 90.],\n",
            "        [73., 80., 75.]]), tensor([[180.],\n",
            "        [152.]])]\n",
            "Epoch:   16/20 Batch:1/3 Cost: 2.34102\n",
            "1\n",
            "[tensor([[ 93.,  88.,  93.],\n",
            "        [ 96.,  98., 100.]]), tensor([[185.],\n",
            "        [196.]])]\n",
            "Epoch:   16/20 Batch:2/3 Cost: 16.65487\n",
            "2\n",
            "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
            "Epoch:   16/20 Batch:3/3 Cost: 27.70496\n",
            "0\n",
            "[tensor([[ 73.,  66.,  70.],\n",
            "        [ 96.,  98., 100.]]), tensor([[142.],\n",
            "        [196.]])]\n",
            "Epoch:   17/20 Batch:1/3 Cost: 12.16940\n",
            "1\n",
            "[tensor([[73., 80., 75.],\n",
            "        [89., 91., 90.]]), tensor([[152.],\n",
            "        [180.]])]\n",
            "Epoch:   17/20 Batch:2/3 Cost: 15.18667\n",
            "2\n",
            "[tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
            "Epoch:   17/20 Batch:3/3 Cost: 15.66679\n",
            "0\n",
            "[tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  80.,  75.]]), tensor([[196.],\n",
            "        [152.]])]\n",
            "Epoch:   18/20 Batch:1/3 Cost: 17.78223\n",
            "1\n",
            "[tensor([[89., 91., 90.],\n",
            "        [73., 66., 70.]]), tensor([[180.],\n",
            "        [142.]])]\n",
            "Epoch:   18/20 Batch:2/3 Cost: 13.80517\n",
            "2\n",
            "[tensor([[93., 88., 93.]]), tensor([[185.]])]\n",
            "Epoch:   18/20 Batch:3/3 Cost: 10.56071\n",
            "0\n",
            "[tensor([[ 89.,  91.,  90.],\n",
            "        [ 96.,  98., 100.]]), tensor([[180.],\n",
            "        [196.]])]\n",
            "Epoch:   19/20 Batch:1/3 Cost: 13.28258\n",
            "1\n",
            "[tensor([[73., 80., 75.],\n",
            "        [93., 88., 93.]]), tensor([[152.],\n",
            "        [185.]])]\n",
            "Epoch:   19/20 Batch:2/3 Cost: 12.75901\n",
            "2\n",
            "[tensor([[73., 66., 70.]]), tensor([[142.]])]\n",
            "Epoch:   19/20 Batch:3/3 Cost: 22.02232\n",
            "0\n",
            "[tensor([[ 96.,  98., 100.],\n",
            "        [ 89.,  91.,  90.]]), tensor([[196.],\n",
            "        [180.]])]\n",
            "Epoch:   20/20 Batch:1/3 Cost: 13.50382\n",
            "1\n",
            "[tensor([[73., 66., 70.],\n",
            "        [93., 88., 93.]]), tensor([[142.],\n",
            "        [185.]])]\n",
            "Epoch:   20/20 Batch:2/3 Cost: 17.43385\n",
            "2\n",
            "[tensor([[73., 80., 75.]]), tensor([[152.]])]\n",
            "Epoch:   20/20 Batch:3/3 Cost: 26.32259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_var= torch.FloatTensor([[73,80,75]])\n",
        "pred_y= model(new_var)\n",
        "print('훈련 후 입력이 73,80,75일 때의 예측값:', pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neag32VmiI9d",
        "outputId": "1d7b25d0-4f1f-41a5-91fb-dfd16a5632f9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 73,80,75일 때의 예측값: tensor([[155.3497]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tFZjEkA4i3Ab"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}